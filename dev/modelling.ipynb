{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "dir_data = pathlib.Path(\"../data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlm12rag.etl import etl_data_from_kaggle\n",
    "\n",
    "etl_data_from_kaggle(dataset=\"rtatman/questionanswer-dataset\", dst=dir_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "dir_data = pathlib.Path(\"../data_sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "document_loader = DirectoryLoader(dir_data, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [Document(page_content='the dry bog\\n\\nalongside the shire of ag45i4nt there is a river that flows into a bog. all the water of the large river flows into it, but the bog is dry. not a single soul understands why. but the bog near the ag45i4nt shire is completely dry.', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='the 4831asx eye less\\n\\nnobody on the street would defy johnathan ferg-simons anymore. he is wearing his new eye glasses, the 4831asx. he can see through walls and shoot lasers. everybody is afraid of mr ferg-simons.', metadata={'source': '../data_sample/cyber-punk.txt'}),\n",
       "  Document(page_content=\"the last kingdom\\n\\narguslweruna is the king here, but he doesn't care about people. he does as he pleases, drunk all day, barely ever listen to what needs to be done. however, in a moment of need, he put his life on the line and fought for everyone. and this is why people love him.\", metadata={'source': '../data_sample/the-last-kingdom.txt'})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = document_loader.load()\n",
    "(len(documents), documents[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,\n",
       " [Document(page_content='the dry bog', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='alongside the shire of ag45i4nt there is a river', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='that flows into a bog. all the water of the large', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='river flows into it, but the bog is dry. not a', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='a single soul understands why. but the bog near', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='near the ag45i4nt shire is completely dry.', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='the 4831asx eye less', metadata={'source': '../data_sample/cyber-punk.txt'}),\n",
       "  Document(page_content='nobody on the street would defy johnathan', metadata={'source': '../data_sample/cyber-punk.txt'}),\n",
       "  Document(page_content='ferg-simons anymore. he is wearing his new eye', metadata={'source': '../data_sample/cyber-punk.txt'}),\n",
       "  Document(page_content='eye glasses, the 4831asx. he can see through', metadata={'source': '../data_sample/cyber-punk.txt'})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=5)\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "(len(document_chunks), document_chunks[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Lab/interview-training/document-rag/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.docarray.in_memory.DocArrayInMemorySearch at 0x13e941060>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.docarray import DocArrayInMemorySearch\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "vector_store = DocArrayInMemorySearch.from_documents(document_chunks, embeddings)\n",
    "vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x12e995a50>, model_id='google/flan-t5-small', model_kwargs={'temperature': 0.01, 'max_length': 128, 'do_sample': True}, pipeline_kwargs={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    task=\"text2text-generation\",\n",
    "    model_id=\"google/flan-t5-small\",\n",
    "    model_kwargs=dict(temperature=0.01, max_length=128, do_sample=True),\n",
    ")\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "qa_rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "qa_rag_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x12e995a50>, model_id='google/flan-t5-small', model_kwargs={'temperature': 0.01, 'max_length': 128, 'do_sample': True}, pipeline_kwargs={})), document_variable_name='context'), return_source_documents=True, retriever=VectorStoreRetriever(tags=['DocArrayInMemorySearch'], vectorstore=<langchain.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x13e941060>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": qa_rag_prompt},\n",
    "    return_source_documents=True,\n",
    ")\n",
    "qa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question) -> str:\n",
    "    result = qa({\"query\": question})\n",
    "    return result[\"result\"], result[\"source_documents\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hudsonmendes/Lab/interview-training/document-rag/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('people',\n",
       " [Document(page_content=\"arguslweruna is the king here, but he doesn't\", metadata={'source': '../data_sample/the-last-kingdom.txt'}),\n",
       "  Document(page_content='and this is why people love him.', metadata={'source': '../data_sample/the-last-kingdom.txt'}),\n",
       "  Document(page_content='his life on the line and fought for everyone. and', metadata={'source': '../data_sample/the-last-kingdom.txt'}),\n",
       "  Document(page_content='care about people. he does as he pleases, drunk', metadata={'source': '../data_sample/the-last-kingdom.txt'})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"Who loves arguslweruna?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('king',\n",
       " [Document(page_content=\"arguslweruna is the king here, but he doesn't\", metadata={'source': '../data_sample/the-last-kingdom.txt'}),\n",
       "  Document(page_content='his life on the line and fought for everyone. and', metadata={'source': '../data_sample/the-last-kingdom.txt'}),\n",
       "  Document(page_content='and this is why people love him.', metadata={'source': '../data_sample/the-last-kingdom.txt'}),\n",
       "  Document(page_content='care about people. he does as he pleases, drunk', metadata={'source': '../data_sample/the-last-kingdom.txt'})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What's arguslweruna role?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dry',\n",
       " [Document(page_content='the dry bog', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='that flows into a bog. all the water of the large', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='river flows into it, but the bog is dry. not a', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='a single soul understands why. but the bog near', metadata={'source': '../data_sample/the-dry-bog.txt'})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is the bog near ag45i4nt like?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('shooting lasers',\n",
       " [Document(page_content='the 4831asx eye less', metadata={'source': '../data_sample/cyber-punk.txt'}),\n",
       "  Document(page_content='eye glasses, the 4831asx. he can see through', metadata={'source': '../data_sample/cyber-punk.txt'}),\n",
       "  Document(page_content='alongside the shire of ag45i4nt there is a river', metadata={'source': '../data_sample/the-dry-bog.txt'}),\n",
       "  Document(page_content='walls and shoot lasers. everybody is afraid of mr', metadata={'source': '../data_sample/cyber-punk.txt'})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is 4831asx capable of?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
